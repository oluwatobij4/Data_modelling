{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/home\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\" \n",
    "    CREATE KEYSPACE IF NOT EXISTS sparkfly\n",
    "    WITH REPLICATION= \n",
    "    {'class': 'SimpleStrategy', 'replication_factor':1}\"\"\"\n",
    ")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.set_keyspace('sparkfly')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data from file into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "df = pd.read_csv('event_datafile_new.csv')\n",
    "df['user']= df['firstName'] + ' ' + df['lastName'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1: Getting artist, song name and lenght through session ID and Item in session\n",
    "our prmary key is a composite key (SessionId and itemInSession) because of the desired result, as with nosql databases like Apache cassandra, we must model the database after the query hence why the primary key is a composite key consisting of session_Id as the partition_key and itemin session as the clustering key for a fast retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query statement\n",
    "query = \"select artist, song, length from playlist_history where sessionid=338 and iteminsession=4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table with condition in keyspace\n",
    "query = \"CREATE TABLE IF NOT EXISTS playlist_history\"\n",
    "query = query + \"(sessionId int, itemInSession int, artist text, song text, length double, PRIMARY KEY (sessionId, itemInSession))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#insert data into table\n",
    "query = \"INSERT INTO playlist_history (sessionId, ItemInSession, artist, song, length)\"\n",
    "query = query + \" VALUES (%s, %s, %s, %s, %s)\"  \n",
    "for index, row in df.iterrows():\n",
    "    session.execute(query, ( row['sessionId'],row['itemInSession'],  row['artist'], row['song'], row['length']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338 4 Faithless 495.3073 Music Matters (Mark Knight Dub)\n"
     ]
    }
   ],
   "source": [
    "#run query to verify result\n",
    "query = \"select * from playlist_history WHERE sessionId=338 and itemInSession=4\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "for row in rows:\n",
    "    print(row.sessionid, row.iteminsession, row.artist, row.length, row.song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task2: Getting artist, song (sorted by item in session) and user (first name and last name) through user id  and session id.\n",
    "our primary key here  is also a composite key : user id  and session id are the partition key because the data model must follow desired resultfor fast and efficient retrieval while  item in session as the clustering key which is also known as the sorting key to satisfy the query condition for the song to be sorted. \n",
    "A new column 'user' has been created in the dataframe to satisfy the query condition and work optimally in the nosql database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query statement\n",
    "query = \"select artist, song, user from artist_by_user where userId=10 and sessionId=182\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table with condition in keyspace\n",
    "query = \"CREATE TABLE IF NOT EXISTS artist_by_user\"\n",
    "query = query + \"(userId int, sessionId int, song text, itemInSession int, user text, artist text,PRIMARY KEY ((userId,sessionId),itemInSession))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert data into table\n",
    "query = \"INSERT INTO artist_by_user (userId, sessionId, itemInSession, song, user, artist)\"\n",
    "query = query + \" VALUES (%s, %s, %s, %s, %s,%s)\"\n",
    "    \n",
    "for index, row in df.iterrows():\n",
    "    session.execute(query, (row['userId'], row['sessionId'], row['itemInSession'], row['song'], row['user'], row['artist']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down To The Bone Keep On Keepin' On Sylvie Cruz\n",
      "Three Drives Greece 2000 Sylvie Cruz\n",
      "Sebastien Tellier Kilometer Sylvie Cruz\n",
      "Lonnie Gordon Catch You Baby (Steve Pitron & Max Sanna Radio Edit) Sylvie Cruz\n"
     ]
    }
   ],
   "source": [
    "#run query to verify result\n",
    "query = \"select artist, song, user from artist_by_user where userId=10 and sessionId=182\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "for row in rows:\n",
    "    print( row.artist, row.song, row.user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task3: Getting every user for a particular song \n",
    "our primary key here is  a composite key : song, user and userId because using song and user alone as partition increases the danger of duplicates in case where different users with same usernames listen to the same song, the query will retrieve only one of these entries, this is olved by throwing in a column that makes the identity of the user unique, and in this case it's the user id.\n",
    "A new column 'user' has been created in the dataframe to satisfy the query condition and work optimally in the nosql database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query statement\n",
    "query = \"select song, user from users_by_song where song = 'All Hands Against His Own'\"                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table with condiiton in keyspace\n",
    "query = \"CREATE TABLE IF NOT EXISTS users_by_song\"\n",
    "query = query + \"( song text,user text, userId int, artist text,PRIMARY KEY (song, user,userId ))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert data into table\n",
    "query = \"INSERT INTO users_by_song (song, user,userId, artist)\"\n",
    "query = query + \" VALUES (%s, %s, %s, %s)\"\n",
    "  \n",
    "for index, row in df.iterrows():\n",
    "    session.execute(query, (row['song'], row['user'], row['userId'], row['artist']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacqueline Lynch All Hands Against His Own\n",
      "Sara Johnson All Hands Against His Own\n",
      "Tegan Levine All Hands Against His Own\n"
     ]
    }
   ],
   "source": [
    "#run query to verify result\n",
    "query = \"select song, user from users_by_song where song = 'All Hands Against His Own' \"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "for row in rows:\n",
    "    print( row.user, row.song )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables drop before closing connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in ['playlist_history', 'artist_by_user','users_by_song']:\n",
    "    query = f\"DROP TABLE {t}\"\n",
    "    try:\n",
    "        rows = session.execute(query)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session and cluster connection shutdownÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
